{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uGRz9iW3qC1x"
   },
   "source": [
    "# MuZero\n",
    "\n",
    "This notebook is just an example to show how to run [MuZero (https://github.com/werner-duvaud/muzero-general)](https://github.com/werner-duvaud/muzero-general) in Google Colab or Jupyter Notebook. You can also launch MuZero directly by cloning the github repository and running the command `python muzero.py`. See [readme](https://github.com/werner-duvaud/muzero-general) for detailed instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_torch = torch.tensor([[-0.0078,  0.4007, -0.1592,  0.3446,  0.2232, -0.0814, -0.1400,  0.6435,\n",
    "                     0.5683, -0.4653, -0.3925,  0.0400,  0.1729, -0.0152,  0.0551, -0.1042,\n",
    "                     0.5908,  0.0915,  0.2475,  0.2067, -0.5062]])\n",
    "support_size_torch = 10\n",
    "x_torch = torch.tensor([[-0.4167]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stonks: tensor([[-10,  -9,  -8,  -7,  -6,  -5,  -4,  -3,  -2,  -1,   0,   1,   2,   3,\n",
      "           4,   5,   6,   7,   8,   9,  10]])\n",
      "mul stonks: tensor([[-0.4143, -0.5610, -0.2849, -0.4125, -0.3132, -0.1925, -0.1452, -0.2384,\n",
      "         -0.1474, -0.0262,  0.0000,  0.0435,  0.0993,  0.1234,  0.1765,  0.1881,\n",
      "          0.4523,  0.3203,  0.4279,  0.4621,  0.2517]])\n",
      "big stonks: tensor([[-0.1907]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4167]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def support_to_scalar_torch(logits, support_size):\n",
    "    \"\"\"\n",
    "    Transform a categorical representation to a scalar\n",
    "    See paper appendix Network Architecture\n",
    "    \"\"\"\n",
    "    # Decode to a scalar\n",
    "    probabilities = torch.softmax(logits, dim=1)\n",
    "    \n",
    "    print(\"stonks:\",\n",
    "        torch.tensor([x for x in range(-support_size, support_size + 1)])\n",
    "        .expand(probabilities.shape)\n",
    "    )\n",
    "    support = (\n",
    "        torch.tensor([x for x in range(-support_size, support_size + 1)])\n",
    "        .expand(probabilities.shape)\n",
    "        .float()\n",
    "        .to(device=probabilities.device)\n",
    "    )\n",
    "    x = torch.sum(support * probabilities, dim=1, keepdim=True)\n",
    "    print(\"mul stonks:\", support * probabilities)\n",
    "    print(\"big stonks:\", x)\n",
    "\n",
    "    # Invert the scaling (defined in https://arxiv.org/abs/1805.11593)\n",
    "    x = torch.sign(x) * (\n",
    "        ((torch.sqrt(1 + 4 * 0.001 * (torch.abs(x) + 1 + 0.001)) - 1) / (2 * 0.001))\n",
    "        ** 2\n",
    "        - 1\n",
    "    )\n",
    "    return x\n",
    "\n",
    "support_to_scalar_torch(logits_torch, support_size_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_tf = tf.constant([[-0.0078,  0.4007, -0.1592,  0.3446,  0.2232, -0.0814, -0.1400,  0.6435,\n",
    "                     0.5683, -0.4653, -0.3925,  0.0400,  0.1729, -0.0152,  0.0551, -0.1042,\n",
    "                     0.5908,  0.0915,  0.2475,  0.2067, -0.5062]])\n",
    "support_size_tf = 10\n",
    "x_tf = tf.constant([[-0.4167]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-0.41668355]], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def support_to_scalar_tf(logits, support_size):\n",
    "    \"\"\"\n",
    "    Transform a categorical representation to a scalar\n",
    "    See paper appendix Network Architecture\n",
    "    \"\"\"\n",
    "    # Decode to a scalar\n",
    "    probabilities = tf.nn.softmax(logits, axis=1)\n",
    "    support = tf.constant([x for x in range(-support_size, support_size + 1)], dtype=tf.float32)\n",
    "    support = tf.broadcast_to(support, probabilities.shape)\n",
    "    x = tf.math.reduce_sum(support * probabilities, axis=1, keepdims=True)\n",
    "    \n",
    "    # Invert the scaling (defined in https://arxiv.org/abs/1805.11593)\n",
    "    x = tf.math.sign(x) * (\n",
    "        ((tf.math.sqrt(1 + 4 * 0.001 * (tf.math.abs(x) + 1 + 0.001)) - 1) / (2 * 0.001))\n",
    "        ** 2\n",
    "        - 1\n",
    "    )\n",
    "    return x\n",
    "\n",
    "support_to_scalar_tf(logits_tf, support_size_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scalar to support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stonks: tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n",
      "stonks: torch.Size([16, 6, 21])\n"
     ]
    }
   ],
   "source": [
    "def scalar_to_support_torch(x, support_size):\n",
    "    \"\"\"\n",
    "    Transform a scalar to a categorical representation with (2 * support_size + 1) categories\n",
    "    See paper appendix Network Architecture\n",
    "    \"\"\"\n",
    "    # Reduce the scale (defined in https://arxiv.org/abs/1805.11593)\n",
    "    x = torch.sign(x) * (torch.sqrt(torch.abs(x) + 1) - 1) + 0.001 * x\n",
    "\n",
    "    # Encode on a vector\n",
    "    x = torch.clamp(x, -support_size, support_size)\n",
    "    floor = x.floor()\n",
    "    prob = x - floor\n",
    "#     print(\"prob:\", prob.shape)\n",
    "    logits = torch.zeros(x.shape[0], x.shape[1], 2 * support_size + 1).to(x.device)\n",
    "    logits.scatter_(\n",
    "        2, (floor + support_size).long().unsqueeze(-1), (1 - prob).unsqueeze(-1)\n",
    "    )\n",
    "    print(\"stonks:\", logits)\n",
    "    print(\"stonks:\", logits.shape)\n",
    "    indexes = floor + support_size + 1\n",
    "    prob = prob.masked_fill_(2 * support_size < indexes, 0.0)\n",
    "    indexes = indexes.masked_fill_(2 * support_size < indexes, 0.0)\n",
    "    logits.scatter_(2, indexes.long().unsqueeze(-1), prob.unsqueeze(-1))\n",
    "#     return logits\n",
    "\n",
    "scalar_to_support_torch(\n",
    "    torch.tensor([[2.1025, 2.0129, 2.1019, 2.0780, 2.0724, 2.0395],\n",
    "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [2.1156, 1.9219, 1.9878, 2.0014, 2.0230, 1.9698],\n",
    "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [1.9868, 2.0178, 2.1383, 1.9936, 2.0089, 1.9848],\n",
    "        [1.9503, 1.9601, 2.0509, 1.9869, 1.9181, 1.9885],\n",
    "        [2.0072, 1.9588, 2.0606, 2.0278, 2.0264, 2.0652]]), \n",
    "    support_size_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stonks: tf.Tensor(\n",
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]], shape=(16, 6, 21), dtype=float32)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "scatter_nd() missing 1 required positional argument: 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-21c88b27ad7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0;36m1.9503\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.9601\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.0509\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.9869\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.9181\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.9885\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         [2.0072, 1.9588, 2.0606, 2.0278, 2.0264, 2.0652]]), \n\u001b[0;32m---> 44\u001b[0;31m     support_size_tf)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-50-21c88b27ad7b>\u001b[0m in \u001b[0;36mscalar_to_support_tf\u001b[0;34m(x, support_size)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"stonks:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     logits = tf.scatter_nd(\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloor\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msupport_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# shape required, account for dims=2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     )\n\u001b[1;32m     20\u001b[0m     \u001b[0mindexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloor\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msupport_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: scatter_nd() missing 1 required positional argument: 'shape'"
     ]
    }
   ],
   "source": [
    "def scalar_to_support_tf(x, support_size):\n",
    "    \"\"\"\n",
    "    Transform a scalar to a categorical representation with (2 * support_size + 1) categories\n",
    "    See paper appendix Network Architecture\n",
    "    \"\"\"\n",
    "    # Reduce the scale (defined in https://arxiv.org/abs/1805.11593)\n",
    "    x = tf.math.sign(x) * (tf.math.sqrt(tf.math.abs(x) + 1) - 1) + 0.001 * x\n",
    "\n",
    "    # Encode on a vector\n",
    "    x = tf.clip_by_value(x, -support_size, support_size)\n",
    "#     print(\"x:\", x)\n",
    "    floor = tf.math.floor(x)\n",
    "    prob = x - floor\n",
    "#     print(\"prob:\", prob.shape)\n",
    "    logits = tf.zeros([x.shape[0], x.shape[1], 2 * support_size + 1])\n",
    "    logits = tf.scatter_nd(\n",
    "        tf.expand_dims(floor + support_size, -1), tf.expand_dims(1 - prob, -1) # shape required, account for dims=2\n",
    "    )\n",
    "    print(\"stonks:\", logits)\n",
    "    indexes = floor + support_size + 1\n",
    "    prob = tf.where(2 * support_size < indexes, prob, 0.0)\n",
    "    indexes = tf.where(2 * support_size < indexes, indexes, 0.0)\n",
    "    logits.tf.scatter_nd(\n",
    "        tf.expand_dims(indexes.long(), -1), tf.expand_dims(prob, -1) # shape required, account for dims=2\n",
    "    )\n",
    "#     return logits\n",
    "scalar_to_support_tf(\n",
    "    tf.constant([[2.1025, 2.0129, 2.1019, 2.0780, 2.0724, 2.0395],\n",
    "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [2.1156, 1.9219, 1.9878, 2.0014, 2.0230, 1.9698],\n",
    "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [1.9868, 2.0178, 2.1383, 1.9936, 2.0089, 1.9848],\n",
    "        [1.9503, 1.9601, 2.0509, 1.9869, 1.9181, 1.9885],\n",
    "        [2.0072, 1.9588, 2.0606, 2.0278, 2.0264, 2.0652]]), \n",
    "    support_size_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
